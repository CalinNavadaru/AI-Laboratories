{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Azure",
   "id": "e65a69616cd3149f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import random\n",
    "\n",
    "import numpy\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ],
   "id": "3f24c6c0958e5d67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "endpoint = \"https://nlpnavadarucalin.cognitiveservices.azure.com/\"\n",
    "key = \"<template>\"\n",
    "\n",
    "client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))"
   ],
   "id": "5803bfc733f4ef9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "message1 = [\n",
    "    \"By choosing a bike over a car, I’m reducing my environmental footprint. Cycling promotes eco-friendly transportation, and I’m proud to be part of that movement..\"]\n",
    "\n",
    "result = client.analyze_sentiment(message1, show_opinion_mining=True)\n",
    "docs = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "for idx, doc in enumerate(docs):\n",
    "    print(doc.sentiment)"
   ],
   "id": "1f12cd4db45d3799",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/reviews_mixed.csv\")\n",
    "data"
   ],
   "id": "d312ccae9f42ee5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "list_reviews = data['Text'].to_list()\n",
    "sentiments_reviews = data['Sentiment'].to_list()\n",
    "ground_truth = pd.factorize(data['Sentiment'])"
   ],
   "id": "b62d90a4fa4e6c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predicted = []\n",
    "for id_review, values in enumerate(zip(list_reviews, sentiments_reviews)):\n",
    "    review, sentiment = values\n",
    "    result_reviews = client.analyze_sentiment([review], show_opinion_mining=True)\n",
    "    result_docs = [doc for doc in result_reviews if not doc.is_error]\n",
    "    for review_text in result_docs:\n",
    "        print(f'Review: {review} -> {review_text.sentiment}')\n",
    "        if review_text.sentiment == \"positive\":\n",
    "            predicted.append(1)\n",
    "        else:\n",
    "            predicted.append(0)"
   ],
   "id": "cbfe52c0c214b44f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(predicted)\n",
    "ground_truth = ground_truth[0]\n",
    "print(ground_truth)"
   ],
   "id": "4e9b5ca373bf60ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy {accuracy_score(predicted, ground_truth)}')"
   ],
   "id": "5642dfb578350228",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# k-Means Library",
   "id": "4fa9e419abb19181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "msg = message1[0].split()\n",
    "result = 0\n",
    "for word in msg:\n",
    "    word = word.strip()\n",
    "    result += word2vec_model[word] if len(word) > 2 and word in word2vec_model.index_to_key else 0\n",
    "\n",
    "result = result / len(msg)\n",
    "print(result)"
   ],
   "id": "7378e2e4e9ec1de5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import shuffle\n",
    "\n",
    "indexes = [i for i in range(len(list_reviews))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.78 * len(indexes))]\n",
    "train_input = [list_reviews[i] for i in train_indexes]\n",
    "test_input = [list_reviews[i] for i in indexes if i not in train_indexes]\n",
    "test_output = [ground_truth[i] for i in indexes if i not in train_indexes]"
   ],
   "id": "978c7802e047f055",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_feature_w2v(data_arg):\n",
    "    result_list = []\n",
    "    for prop in data_arg:\n",
    "        feature = 0\n",
    "        list_words = prop.split()\n",
    "        for word_arg in list_words:\n",
    "            word_arg = word_arg.strip()\n",
    "            if word_arg in word2vec_model.index_to_key and len(word_arg) > 2:\n",
    "                feature += np.mean(word2vec_model[word_arg])\n",
    "            else:\n",
    "                feature += 0\n",
    "\n",
    "        feature = feature / len(list_words)\n",
    "        result_list.append(feature)\n",
    "\n",
    "    return numpy.array(result_list).reshape(-1, 1)"
   ],
   "id": "a5793875c8bfd265",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_input = train_feature_w2v(train_input)\n",
    "test_input = train_feature_w2v(test_input)"
   ],
   "id": "a58241cd70a15eb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "unsupervisedClassifier = KMeans(n_clusters=2, random_state=0)\n",
    "unsupervisedClassifier.fit(train_input)"
   ],
   "id": "6f1328232e91dce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predicted = unsupervisedClassifier.predict(test_input)\n",
    "print(predicted)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy {accuracy_score(predicted, test_output)}')"
   ],
   "id": "4d435474529f861b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Caracteristici Text",
   "id": "91b45e6dde9d385f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Word2Vec",
   "id": "badccf5d5314361f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(train_feature_w2v(list_reviews))",
   "id": "a2a45d49eacc46a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Bag of words",
   "id": "65e95b2095e34f5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ],
   "id": "5838058f4cdc4d13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "indexes = [i for i in range(len(list_reviews))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.78 * len(indexes))]\n",
    "train_input = [list_reviews[i] for i in train_indexes]\n",
    "test_input = [list_reviews[i] for i in indexes if i not in train_indexes]"
   ],
   "id": "1dcc49b0587ba086",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_input = vectorizer.fit_transform(train_input)\n",
    "test_input = vectorizer.transform(test_input)"
   ],
   "id": "a353b40607bcdcd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(type(train_input))",
   "id": "a40acc19c7d31df2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"vocab size: \", len(vectorizer.vocabulary_), \" words\")\n",
    "print(\"trainFeatures shape: \", train_input.shape)\n",
    "\n",
    "print('some words of the vocab: ', vectorizer.get_feature_names_out()[-20:])\n",
    "print('some features: ', train_input.toarray()[:3])"
   ],
   "id": "70876d3281d8c717",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TF-IDF",
   "id": "8ee7ef469ae559c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "indexes = [i for i in range(len(list_reviews))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.78 * len(indexes))]\n",
    "train_input = [list_reviews[i] for i in train_indexes]\n",
    "test_input = [list_reviews[i] for i in indexes if i not in train_indexes]"
   ],
   "id": "11a5cdae7ddf2ca5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=50)\n",
    "\n",
    "trainFeatures = vectorizer.fit_transform(train_input)\n",
    "testFeatures = vectorizer.transform(test_input)\n",
    "\n",
    "print('vocab: ', vectorizer.get_feature_names_out()[:10])\n",
    "print('features: ', trainFeatures.toarray()[:3])"
   ],
   "id": "c7826ccdf813629",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extra ",
   "id": "c5e31bfbde6bf6fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### CBOW",
   "id": "3336ebdcb1656f3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "indexes = [i for i in range(len(list_reviews))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.78 * len(indexes))]\n",
    "train_input = [list_reviews[i] for i in train_indexes]"
   ],
   "id": "a6f81f3a37381a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "train_input = [word_tokenize(review) for review in train_input]"
   ],
   "id": "9be0d356e55e3b2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "cbow_model = Word2Vec(train_input, min_count=1, window=5, sg=0)\n",
    "\n",
    "cbow_model.train(train_input, total_examples=len(train_input), epochs=100)\n",
    "print(cbow_model.wv)"
   ],
   "id": "b17db48892da9572",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cosine Similarity",
   "id": "f6c07a92298186dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "propozitia1 = \"Eu sunt Calin.\"\n",
    "propozitia2 = \"Eu nu sunt Calin, sunt Marius.\"\n",
    "\n",
    "distance = word2vec_model.wmdistance(propozitia1, propozitia2)\n",
    "print(distance)"
   ],
   "id": "56e0fc8442888570",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# K-means manual",
   "id": "cf4455c5ca09d702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def euclidian_distance(a, b):\n",
    "    sum_value = 0\n",
    "    for elem_a, elem_b in zip(a, b):\n",
    "        sum_value += (elem_a - elem_b) ** 2\n",
    "    return math.sqrt(np.sum(sum_value))"
   ],
   "id": "9753749d374abf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def stop(old_c, c, no_iteration):\n",
    "    if no_iteration > 10000:\n",
    "        return True\n",
    "    return old_c == c\n",
    "\n",
    "\n",
    "class KMeans:\n",
    "\n",
    "    def __init__(self, input_size, number_of_classes):\n",
    "        self.input_size = input_size\n",
    "        self.centroids = None\n",
    "        self.number_of_classes = number_of_classes\n",
    "\n",
    "    def fit(self, train_data_arg):\n",
    "        values_random = random.sample(list(train_data_arg), self.number_of_classes)\n",
    "        self.centroids = np.array([[x] for x in values_random])\n",
    "        no_iteration = 0\n",
    "        old_c = None\n",
    "        c = []\n",
    "        while not stop(old_c, c, no_iteration):\n",
    "            old_c = c.copy()\n",
    "            c = []\n",
    "            no_iteration += 1\n",
    "            for i in range(len(train_data_arg)):\n",
    "                # c_min = np.linalg.norm(self.centroids[0] - train_data_arg[i])\n",
    "                c_min = euclidian_distance(self.centroids[0], train_data_arg[i])\n",
    "                c_index = 0\n",
    "                for j in range(1, len(self.centroids)):\n",
    "                    # d = np.linalg.norm(self.centroids[j] - train_data_arg[i])\n",
    "                    d = euclidian_distance(self.centroids[j], train_data_arg[i])\n",
    "                    if c_min > d:\n",
    "                        c_index = j\n",
    "                        c_min = d\n",
    "                c.append(c_index)\n",
    "\n",
    "            for j in range(len(self.centroids)):\n",
    "                denominator = 0\n",
    "                numerator = 0\n",
    "                for i in range(len(c)):\n",
    "                    if c[i] == j:\n",
    "                        numerator += train_data_arg[i]\n",
    "                        denominator += 1\n",
    "\n",
    "                self.centroids[j] = numerator / denominator if denominator != 0 \\\n",
    "                    else train_data_arg[random.randint(0, len(train_data_arg) - 1)]\n",
    "\n",
    "    def predict(self, test_data_arg):\n",
    "        result_predict = []\n",
    "        for i in range(len(test_data_arg)):\n",
    "            c_min = np.linalg.norm(self.centroids[0] - test_data_arg[i])\n",
    "            c_index = 0\n",
    "            for j in range(1, len(self.centroids)):\n",
    "                d = euclidian_distance(self.centroids[j], test_data_arg[i])\n",
    "                if c_min > d:\n",
    "                    c_index = j\n",
    "                    c_min = d\n",
    "\n",
    "            result_predict.append(c_index)\n",
    "\n",
    "        return result_predict"
   ],
   "id": "aba60adb5744ab49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import shuffle\n",
    "\n",
    "indexes = [i for i in range(len(list_reviews))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.75 * len(indexes))]\n",
    "train_input = [list_reviews[i] for i in train_indexes]\n",
    "test_input = [list_reviews[i] for i in indexes if i not in train_indexes]\n",
    "test_output = [ground_truth[i] for i in indexes if i not in train_indexes]\n",
    "\n",
    "train_input = train_feature_w2v(train_input)\n",
    "test_input = train_feature_w2v(test_input)"
   ],
   "id": "e3401905e581054e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unsupervisedClassifier = KMeans(1, 2)\n",
    "unsupervisedClassifier.fit(train_input)\n",
    "predicted = unsupervisedClassifier.predict(test_input)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy {accuracy_score(predicted, test_output)}')"
   ],
   "id": "67390bb76f4782e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Alternative la K-means",
   "id": "a11bb97f90712f2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import shuffle\n",
    "\n",
    "indexes = [i for i in range(len(list_reviews))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.75 * len(indexes))]\n",
    "train_input = [list_reviews[i] for i in train_indexes]\n",
    "test_input = [list_reviews[i] for i in indexes if i not in train_indexes]\n",
    "test_output = [ground_truth[i] for i in indexes if i not in train_indexes]\n",
    "\n",
    "train_input = train_feature_w2v(train_input)\n",
    "test_input = train_feature_w2v(test_input)"
   ],
   "id": "234522b4361c9da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "# Apply Mean Shift clustering\n",
    "ms = MeanShift()\n",
    "ms.fit(train_input)\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Number of clusters\n",
    "n_clusters = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated clusters:\", n_clusters)\n",
    "print(cluster_centers)\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(train_input[:, 0], np.zeros_like(train_input[:, 0]), c=labels, cmap='viridis')\n",
    "plt.scatter(cluster_centers[:, 0], np.zeros_like(cluster_centers), marker='x', color='red', s=100, linewidths=4)\n",
    "plt.title('Estimated number of clusters: {}'.format(n_clusters))\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ],
   "id": "33441ba18bad8a6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predicted = ms.predict(test_input)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy {accuracy_score(predicted, test_output)}')"
   ],
   "id": "1e3473cdbdf28709",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import shuffle\n",
    "\n",
    "indexes = [i for i in range(len(list_reviews))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.75 * len(indexes))]\n",
    "train_input = [list_reviews[i] for i in train_indexes]\n",
    "test_input = [list_reviews[i] for i in indexes if i not in train_indexes]\n",
    "test_output = [ground_truth[i] for i in indexes if i not in train_indexes]\n",
    "\n",
    "train_input = train_feature_w2v(train_input)\n",
    "test_input = train_feature_w2v(test_input)"
   ],
   "id": "51213bddd463669a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "spectral_clustering = SpectralClustering(n_clusters=1, affinity='nearest_neighbors', random_state=0)\n",
    "spectral_clustering.fit(train_input)\n",
    "\n",
    "predicted = spectral_clustering.fit_predict(test_input)"
   ],
   "id": "1da0008ca126a962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy {accuracy_score(predicted, test_output)}')"
   ],
   "id": "e1bd46c8125023e9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
