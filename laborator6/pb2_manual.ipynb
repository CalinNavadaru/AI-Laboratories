{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def sigmoid(value):\n",
    "    from math import exp\n",
    "    return 1 / (1 + exp(-value))\n",
    "\n",
    "\n",
    "class MyLogisticRegressor:\n",
    "    def __init__(self, threshold):\n",
    "        self.intercept_ = 0.0\n",
    "        self.coefficients = []\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, x, y, learning_rate=0.0001, no_epochs=100000):\n",
    "        self.coefficients = [0.0 for _ in range(len(x[0]) + 1)]\n",
    "        for epoch in range(no_epochs):\n",
    "            for i in range(len(x)):\n",
    "                y_computed = sigmoid(self.eval(x[i]))\n",
    "                crt_error = y_computed - y[i]\n",
    "                for j in range(0, len(x[0])):\n",
    "                    self.coefficients[j] = self.coefficients[j] - learning_rate * crt_error * y_computed * (\n",
    "                                1 - y_computed) * x[i][j]\n",
    "                self.coefficients[len(x[0])] = self.coefficients[len(x[0])] - learning_rate * crt_error * y_computed * (\n",
    "                            1 - y_computed) * 1\n",
    "\n",
    "        self.intercept_ = self.coefficients[-1]\n",
    "        self.coefficients = self.coefficients[:-1]\n",
    "        print(f\"Coef {self.coefficients}\")\n",
    "        print(f\"Intercept {self.intercept_}\")\n",
    "\n",
    "    def eval(self, xi):\n",
    "        yi = self.coefficients[-1]\n",
    "        for j in range(len(xi)):\n",
    "            yi += self.coefficients[j] * xi[j]\n",
    "        return yi\n",
    "\n",
    "    def compute_label(self, xi):\n",
    "        computed = sigmoid(self.eval(xi))\n",
    "        print(computed)\n",
    "        return 0 if computed < self.threshold else 1\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_computed = [self.compute_label(xi) for xi in x]\n",
    "        return y_computed"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "input_data = breast_cancer_wisconsin_diagnostic.data.features\n",
    "output_data = breast_cancer_wisconsin_diagnostic.data.targets"
   ],
   "id": "39abaddfc342fd1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_data_list = [[r1, t1] for r1, r2, r3, t1, t2, t3 in\n",
    "                   zip(input_data.radius1, input_data.radius2, input_data.radius3, input_data.texture1,\n",
    "                       input_data.texture2, input_data.texture3)]"
   ],
   "id": "93ab0708882f6ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "output_data",
   "id": "4228fb02742a4bb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "output_data_list = [0 if x == \"M\" else 1 for x in output_data.Diagnosis]",
   "id": "a87e93efd0cc1036",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalize_feature(data_arg):\n",
    "    minimum = min(data_arg)\n",
    "    maximum = max(data_arg)\n",
    "    for i in range(len(data_arg)):\n",
    "        data_arg[i] = (data_arg[i] - minimum) / (maximum - minimum)\n",
    "\n",
    "\n",
    "def normalize(train_data_arg):\n",
    "    new_train_data = [[] for _ in range(len(train_data_arg))]\n",
    "    for i in range(len(train_data_arg[0])):\n",
    "        aux_list = [train_data_arg[r][i] for r in range(len(train_data_arg))]\n",
    "        normalize_feature(aux_list)\n",
    "        for t in range(len(train_data_arg)):\n",
    "            new_train_data[t].append(aux_list[t])\n",
    "\n",
    "    return new_train_data\n",
    "\n",
    "\n",
    "def normalisation(train_data, test_data):\n",
    "    if not isinstance(train_data[0], list):\n",
    "        train_data = [[d] for d in train_data]\n",
    "        test_data = [[d] for d in test_data]\n",
    "\n",
    "        normalised_train_data = normalize(train_data)\n",
    "        normalised_test_data = normalize(test_data)\n",
    "\n",
    "        normalised_train_data = [d[0] for d in normalised_train_data]\n",
    "        normalised_test_data = [d[0] for d in normalised_test_data]\n",
    "    else:\n",
    "        normalised_train_data = normalize(train_data)\n",
    "        normalised_test_data = normalize(test_data)\n",
    "\n",
    "    return normalised_train_data, normalised_test_data"
   ],
   "id": "b90ea82ad5aefe9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import shuffle\n",
    "\n",
    "indexes = [i for i in range(len(input_data_list))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.75 * len(input_data_list))]\n",
    "train_input_data = [input_data_list[i] for i in range(len(input_data_list)) if i in train_indexes]\n",
    "test_input_data = [input_data_list[i] for i in range(len(input_data_list)) if i not in train_indexes]\n",
    "train_output_data = [output_data_list[i] for i in range(len(input_data_list)) if i in train_indexes]\n",
    "test_output_data = [output_data_list[i] for i in range(len(input_data_list)) if i not in train_indexes]\n",
    "\n",
    "train_input_data, test_input_data = normalisation(train_input_data, test_input_data)\n",
    "\n",
    "model = MyLogisticRegressor(0.45)\n",
    "model.fit(train_input_data, train_output_data)\n",
    "\n",
    "predicted = model.predict(test_input_data)\n",
    "# print(predicted)"
   ],
   "id": "65172779c92a83aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "err = 0\n",
    "for y, r in zip(predicted, test_output_data):\n",
    "    err += (y - r) ** 2\n",
    "\n",
    "print(f\"Error {err / len(test_output_data)}\")"
   ],
   "id": "a808337b42209bcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = [[18, 10]]\n",
    "result = model.predict(a)\n",
    "if result[0] == 1:\n",
    "    print(\"Malign\")\n",
    "else:\n",
    "    print(\"Benign\")"
   ],
   "id": "73793e4c7228da39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(test_output_data, predicted)\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square=True, cmap='Blues', xticklabels=[\"B\", \"M\"],\n",
    "            yticklabels=[\"B\", \"M\"])\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix', size=15)\n",
    "plt.show()"
   ],
   "id": "754225ffdb47e518",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
