{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def get_mean(data, index):\n",
    "    mean = 0\n",
    "    counter = 0\n",
    "    for row in data:\n",
    "        if row[index].isnumeric():\n",
    "            mean += float(row[index])\n",
    "            counter += 1\n",
    "\n",
    "    return mean / counter\n",
    "\n",
    "\n",
    "def fill(data, index, mean):\n",
    "    for row in data:\n",
    "        if row[index] == '':\n",
    "            row[index] = mean\n",
    "\n",
    "\n",
    "def load_data(file_name, input_variable_name_list, output_variable_name):\n",
    "    print(file_name)\n",
    "    data = []\n",
    "    data_names = []\n",
    "    with open(file_name) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                data_names = row\n",
    "            else:\n",
    "                data.append(row)\n",
    "            line_count += 1\n",
    "    selected_variable1 = data_names.index(input_variable_name_list[0])\n",
    "    selected_variable2 = data_names.index(input_variable_name_list[1])\n",
    "    if file_name == 'C:\\Facultate\\Materii\\AI\\Laboratoare\\laborator5\\data\\\\v3_world-happiness-report-2017.csv':\n",
    "        m1 = get_mean(data, selected_variable1)\n",
    "        m2 = get_mean(data, selected_variable2)\n",
    "        fill(data, selected_variable1, m1)\n",
    "        fill(data, selected_variable2, m2)\n",
    "    input_list = [[float(data[i][selected_variable1]), float(data[i][selected_variable2])] for i in range(len(data))]\n",
    "    selected_output = data_names.index(output_variable_name)\n",
    "    output_list = [float(data[i][selected_output]) for i in range(len(data))]\n",
    "\n",
    "    return input_list, output_list"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_histogram(data, variable_name):\n",
    "    _ = plt.hist(data, 10)\n",
    "    plt.title(\"Histogram of \" + variable_name)\n",
    "    plt.show()"
   ],
   "id": "32d18b040c5086c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "crtDir = os.getcwd()\n",
    "filePath = os.path.join(crtDir, 'data', 'world-happiness-report-2017.csv')\n",
    "\n",
    "inputs, outputs = load_data(filePath, ['Economy..GDP.per.Capita.', 'Freedom'], 'Happiness.Score')\n",
    "print('in:  ', inputs[:5])\n",
    "print('out: ', outputs[:5])\n",
    "\n",
    "f1 = [ex[0] for ex in inputs]\n",
    "f2 = [ex[1] for ex in inputs]\n",
    "plot_histogram(f1, 'capita GDP')\n",
    "plot_histogram(f2, 'freedom')\n",
    "plot_histogram(outputs, 'Happiness score')"
   ],
   "id": "aaa24238b7f1e1c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot3Ddata(x1_train, x2_train, y_train, x1_model=None, x2_model=None, y_model=None, x1_test=None, x2_test=None,\n",
    "               y_test=None,\n",
    "               title=None):\n",
    "    ax = plt.axes(projection='3d')\n",
    "    if x1_train:\n",
    "        ax.scatter(x1_train, x2_train, y_train, c='r', marker='o', label='train data', s=10)\n",
    "    if x1_model:\n",
    "        ax.scatter(x1_model, x2_model, y_model, c='g', marker='_', label='learnt model')\n",
    "    if x1_test:\n",
    "        ax.scatter(x1_test, x2_test, y_test, c='purple', marker='^', label='test data')\n",
    "    plt.title(title)\n",
    "    ax.set_xlabel(\"capita\")\n",
    "    ax.set_ylabel(\"freedom\")\n",
    "    ax.set_zlabel(\"happiness\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "a6d043652435bd6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot3Ddata(f1, f2, outputs, [], [], [], [], [], [], \"capita vs freedom vs happiness\")",
   "id": "ee031dd62c783f10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalisation(train_data, test_data):\n",
    "    def normalize_feature(data_arg):\n",
    "        minimum = min(data_arg)\n",
    "        maximum = max(data_arg)\n",
    "        for i in range(len(data_arg)):\n",
    "            data_arg[i] = (data_arg[i] - minimum) / (maximum - minimum)\n",
    "\n",
    "    def normalize(train_data_arg):\n",
    "        new_train_data = [[] for _ in range(len(train_data_arg))]\n",
    "        for i in range(len(train_data_arg[0])):\n",
    "            aux_list = [train_data_arg[r][i] for r in range(len(train_data_arg))]\n",
    "            normalize_feature(aux_list)\n",
    "            for t in range(len(train_data_arg)):\n",
    "                new_train_data[t].append(aux_list[t])\n",
    "\n",
    "        return new_train_data\n",
    "\n",
    "    if not isinstance(train_data[0], list):\n",
    "        train_data = [[d] for d in train_data]\n",
    "        test_data = [[d] for d in test_data]\n",
    "\n",
    "        normalised_train_data = normalize(train_data)\n",
    "        normalised_test_data = normalize(test_data)\n",
    "\n",
    "        normalised_train_data = [d[0] for d in normalised_train_data]\n",
    "        normalised_test_data = [d[0] for d in normalised_test_data]\n",
    "    else:\n",
    "        normalised_train_data = normalize(train_data)\n",
    "        normalised_test_data = normalize(test_data)\n",
    "\n",
    "    return normalised_train_data, normalised_test_data"
   ],
   "id": "55494e3932662d9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "indexes = [i for i in range(len(inputs))]\n",
    "train_sample = random.sample(indexes, k=int(0.8 * len(inputs)))\n",
    "test_sample = [i for i in range(len(inputs)) if not i in train_sample]\n",
    "\n",
    "train_input_data = [inputs[i] for i in train_sample]\n",
    "train_output_data = [outputs[i] for i in train_sample]\n",
    "test_input_data = [inputs[i] for i in test_sample]\n",
    "test_output_data = [outputs[i] for i in test_sample]\n",
    "\n",
    "train_input_data, test_input_data = normalisation(train_input_data, test_input_data)\n",
    "train_output_data, test_output_data = normalisation(train_output_data, test_output_data)\n",
    "print(train_input_data)\n",
    "\n",
    "f1_train = [t_data[0] for t_data in train_input_data]\n",
    "f2_train = [t_data[1] for t_data in train_input_data]\n",
    "\n",
    "f1_test = [t_test[0] for t_test in test_input_data]\n",
    "f2_test = [t_test[1] for t_test in test_input_data]\n",
    "\n",
    "plot3Ddata(f1_train, f2_train, train_output_data, [], [], [], f1_test, f2_test, test_output_data, \"Test\")"
   ],
   "id": "4acc979586b22ca5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot3Ddata(f1_train, f2_train, train_output_data, [], [], [], f1_test, f2_test, test_output_data, \"Test\")\n",
    "plot_histogram(train_output_data, \"t2\")"
   ],
   "id": "90ab1149a9faa17e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import shuffle\n",
    "def sign(x):\n",
    "    if x < 0:\n",
    "        return -1\n",
    "    elif x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "class MyGDRegression:\n",
    "    def __init__(self):\n",
    "        self.intercept_ = 0.0\n",
    "        self.coefficients = []\n",
    "        self.delta = 1\n",
    "\n",
    "    def fit(self, x, y, learning_rate=0.0001, no_epochs=10000, batch_size=32):\n",
    "        self.coefficients = [0.0 for _ in range(len(x[0]) + 1)]  # coefficients initialization\n",
    "        n_samples = len(x)\n",
    "\n",
    "        for epoch in range(no_epochs):\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                x_batch = x[i:i + batch_size]\n",
    "                y_batch = y[i:i + batch_size]\n",
    "                gradients = self.compute_gradients(x_batch, y_batch)\n",
    "\n",
    "                for j in range(len(x[0])):\n",
    "                    self.coefficients[j] -= learning_rate * gradients[j]\n",
    "                self.coefficients[-1] -= learning_rate * gradients[-1]\n",
    "\n",
    "        self.intercept_ = self.coefficients[-1]\n",
    "        self.coefficients = self.coefficients[:-1]\n",
    "\n",
    "    def eval(self, xi):\n",
    "        yi = self.coefficients[-1]\n",
    "        for j in range(len(xi)):\n",
    "            yi += self.coefficients[j] * xi[j]\n",
    "        return yi\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_computed = [self.eval(xi) for xi in x]\n",
    "        return y_computed\n",
    "\n",
    "    def compute_gradients(self, x, y):\n",
    "        gradients = [0 for _ in range(len(x[0]) + 1)]\n",
    "        for i in range(len(x)):\n",
    "            y_computed = self.eval(x[i])\n",
    "            crt_error = y_computed - y[i]\n",
    "            for j in range(len(x[0])):\n",
    "                gradients[j] += crt_error * x[i][j]\n",
    "            gradients[-1] += crt_error\n",
    "        for j in range(len(gradients)):\n",
    "            gradients[j] /= len(x)\n",
    "        return gradients\n",
    "    \n",
    "    def compute_gradients2(self, x, y):\n",
    "        gradients = [0 for _ in range(len(x[0]) + 1)]\n",
    "    \n",
    "        for i in range(len(x)):\n",
    "            y_computed = self.eval(x[i])\n",
    "            crt_error = y_computed - y[i]\n",
    "    \n",
    "            if abs(crt_error) <= self.delta:\n",
    "                for j in range(len(x[0])):\n",
    "                    gradients[j] += crt_error * crt_error * x[i][j] * 1 / 2\n",
    "                gradients[-1] += crt_error * crt_error * 1 / 2\n",
    "            else:\n",
    "                for j in range(len(x[0])):\n",
    "                    gradients[j] += self.delta * abs(crt_error) - 0.5 * self.delta * self.delta\n",
    "                gradients[-1] += self.delta * abs(crt_error) - 0.5 * self.delta * self.delta\n",
    "    \n",
    "        for j in range(len(gradients)):\n",
    "            gradients[j] /= len(x)\n",
    "    \n",
    "        return gradients\n",
    "    \n",
    "    def compute_gradients3(self, x, y):\n",
    "        gradients = [0 for _ in range(len(x[0]) + 1)]\n",
    "    \n",
    "        for i in range(len(x)):\n",
    "            y_computed = self.eval(x[i])\n",
    "            crt_error = y_computed - y[i]\n",
    "    \n",
    "            for j in range(len(x[0])):\n",
    "                gradients[j] += abs(crt_error) * x[i][j]\n",
    "            gradients[-1] += abs(crt_error)\n",
    "    \n",
    "        for j in range(len(gradients)):\n",
    "            gradients[j] /= len(x)\n",
    "    \n",
    "        return gradients"
   ],
   "id": "629781c6eac2f95b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "regressor = MyGDRegression()\n",
    "\n",
    "regressor.fit(train_input_data, train_output_data)\n",
    "\n",
    "predicted = regressor.predict(test_input_data)\n",
    "print(predicted)"
   ],
   "id": "265aba837e596a1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "no_of_points = 25\n",
    "xref = []\n",
    "val = min(f1)\n",
    "step = (max(f1) - val) / no_of_points\n",
    "for i in range(1, no_of_points):\n",
    "    for j in range(1, no_of_points):\n",
    "        xref.append(val)\n",
    "    val += step\n",
    "\n",
    "xref2 = []\n",
    "val = min(f2)\n",
    "step = (max(f2) - val) / no_of_points\n",
    "for i in range(1, no_of_points):\n",
    "    aux = val\n",
    "    for j in range(1, no_of_points):\n",
    "        xref2.append(aux)\n",
    "        aux += step\n",
    "\n",
    "yref = [regressor.eval([el1, el2]) for el1, el2 in zip(xref, xref2)]\n",
    "plot3Ddata(f1_train, f2_train, train_output_data, xref, xref2, yref, [], [], [], 'train data and the learnt model')"
   ],
   "id": "28db756b7d9cbe40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "computed_test_outputs = regressor.predict(test_input_data)\n",
    "\n",
    "plot3Ddata([], [], [], f1_test, f2_test, computed_test_outputs, f1_test, f2_test, test_output_data, \"prediction\")"
   ],
   "id": "fc381fb2d705827",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "error = 0.0\n",
    "for t1, t2 in zip(computed_test_outputs, test_output_data):\n",
    "    error += (t1 - t2) ** 2\n",
    "error = error / len(test_output_data)\n",
    "print('prediction error (manual): ', error)\n",
    "\n",
    "error2 = 0.0\n",
    "for t1, t2 in zip(computed_test_outputs, test_output_data):\n",
    "    error2 += abs(t1 - t2)\n",
    "error2 = error2 / len(test_output_data)\n",
    "print('predicition error2 (manual with MAE)', error2)"
   ],
   "id": "8fc1992bd51bfa28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_folds = 3\n",
    "n_sample = len(inputs)\n",
    "fold_size = n_sample // n_folds\n",
    "\n",
    "indexes = [i for i in range(n_sample)]\n",
    "shuffle(indexes)\n",
    "\n",
    "for i in range(n_folds):\n",
    "    validation_indices = indexes[i * fold_size: (i + 1) * fold_size]\n",
    "    train_indices = [idx for idx in indexes if idx not in validation_indices]\n",
    "    for j in range(i * fold_size):\n",
    "        train_indices.append(j)\n",
    "    for j in range((i + 1) * fold_size, n_sample):\n",
    "        train_indices.append(j)\n",
    "    \n",
    "    train_inputs_v = [inputs[i] for i in train_indices]\n",
    "    train_outputs_v = [outputs[i] for i in train_indices]\n",
    "\n",
    "    validation_inputs_v = [inputs[i] for i in validation_indices]\n",
    "    validation_outputs_v = [outputs[i] for i in validation_indices]\n",
    "        \n",
    "    model = MyGDRegression()\n",
    "    model.fit(train_inputs_v, train_outputs_v)\n",
    "    prediction = model.predict(validation_inputs_v)\n",
    "    \n",
    "    error = 0.0\n",
    "    for t1, t2 in zip(prediction, validation_outputs_v):\n",
    "        error += (t1 - t2) ** 2\n",
    "    error = error / len(validation_outputs_v)\n",
    "    print('prediction error (manual): ', error)\n",
    "    \n",
    "    error2 = 0.0\n",
    "    for t1, t2 in zip(prediction, validation_outputs_v):\n",
    "        error2 += abs(t1 - t2)\n",
    "    error2 = error2 / len(validation_outputs_v)\n",
    "    print('predicition error2 (manual with MAE)', error2)"
   ],
   "id": "7bd64cc4c3756d4a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
