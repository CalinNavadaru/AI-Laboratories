{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import shuffle\n",
    "def sign(x):\n",
    "    if x < 0:\n",
    "        return -1\n",
    "    elif x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "class MyGDRegression:\n",
    "    def __init__(self):\n",
    "        self.intercept_ = 0.0\n",
    "        self.coefficients = []\n",
    "        self.delta = 1\n",
    "\n",
    "    def fit(self, x, y, learning_rate=0.0001, no_epochs=10000, batch_size=32):\n",
    "        self.coefficients = [0.0 for _ in range(len(x[0]) + 1)]  # coefficients initialization\n",
    "        n_samples = len(x)\n",
    "\n",
    "        for epoch in range(no_epochs):\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                x_batch = x[i:i + batch_size]\n",
    "                y_batch = y[i:i + batch_size]\n",
    "                gradients = self.compute_gradients2(x_batch, y_batch)\n",
    "\n",
    "                for j in range(len(x[0])):\n",
    "                    self.coefficients[j] -= learning_rate * gradients[j]\n",
    "                self.coefficients[-1] -= learning_rate * gradients[-1]\n",
    "\n",
    "        self.intercept_ = self.coefficients[-1]\n",
    "        self.coefficients = self.coefficients[:-1]\n",
    "\n",
    "    def eval(self, xi):\n",
    "        yi = self.coefficients[-1]\n",
    "        for j in range(len(xi)):\n",
    "            yi += self.coefficients[j] * xi[j]\n",
    "        return yi\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_computed = [self.eval(xi) for xi in x]\n",
    "        return y_computed\n",
    "\n",
    "    def compute_gradients(self, x, y):\n",
    "        gradients = [0 for _ in range(len(x[0]) + 1)]\n",
    "        for i in range(len(x)):\n",
    "            y_computed = self.eval(x[i])\n",
    "            crt_error = y_computed - y[i]\n",
    "            for j in range(len(x[0])):\n",
    "                gradients[j] += crt_error * x[i][j]\n",
    "            gradients[-1] += crt_error\n",
    "        for j in range(len(gradients)):\n",
    "            gradients[j] /= len(x)\n",
    "        return gradients\n",
    "    \n",
    "    def compute_gradients2(self, x, y):\n",
    "        gradients = [0 for _ in range(len(x[0]) + 1)]\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            y_computed = self.eval(x[i])\n",
    "            crt_error = y_computed - y[i]\n",
    "\n",
    "            if abs(crt_error) <= self.delta:\n",
    "                for j in range(len(x[0])):\n",
    "                    gradients[j] += crt_error * crt_error * x[i][j]\n",
    "                gradients[-1] += crt_error\n",
    "            else:\n",
    "                for j in range(len(x[0])):\n",
    "                    gradients[j] += (self.delta * sign(crt_error) - 1 / 2 * (self.delta ** 2)) * x[i][j] \n",
    "                gradients[-1] += self.delta * sign(crt_error)\n",
    "\n",
    "        for j in range(len(gradients)):\n",
    "            gradients[j] /= len(x)\n",
    "\n",
    "        return gradients"
   ],
   "id": "f4a3c8036d1ff730",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def load_data(file_name, input_variable_name, output_variable_name):\n",
    "    data = []\n",
    "    data_names = []\n",
    "    with open(file_name) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                data_names = row\n",
    "            else:\n",
    "                data.append(row)\n",
    "            line_count += 1\n",
    "    selected_variable = data_names.index(input_variable_name)\n",
    "    input_list = [float(data[i][selected_variable]) for i in range(len(data))]\n",
    "    selected_output = data_names.index(output_variable_name)\n",
    "    output_list = [float(data[i][selected_output]) for i in range(len(data))]\n",
    "\n",
    "    return input_list, output_list\n",
    "\n",
    "\n",
    "crtDir = os.getcwd()\n",
    "filePath = os.path.join(crtDir, 'data', 'world-happiness-report-2017.csv')\n",
    "\n",
    "inputs, outputs = load_data(filePath, 'Economy..GDP.per.Capita.', 'Happiness.Score')\n",
    "inputs = [[d] for d in inputs]\n",
    "print('in:  ', inputs[:5])\n",
    "print('out: ', outputs[:5])"
   ],
   "id": "811cf68169dbdfc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_histogram(data, variable_name):\n",
    "    _ = plt.hist(data, 10)\n",
    "    plt.title(\"Histogram of \" + variable_name)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_histogram([d[0] for d in inputs], 'Family')\n",
    "plot_histogram(outputs, 'Happiness Score')"
   ],
   "id": "27cdd0ba8ff90c8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(inputs, outputs, 'ro')\n",
    "plt.xlabel('Family')\n",
    "plt.ylabel('happiness')\n",
    "plt.title('Family vs. happiness')\n",
    "plt.show()"
   ],
   "id": "6a93c0158decd8f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "indexes = [i for i in range(len(inputs))]\n",
    "train_sample = random.sample(indexes, k=int(0.75 * len(indexes)))\n",
    "validation_sample = [i for i in indexes if not i in train_sample]\n",
    "\n",
    "train_inputs = [inputs[i] for i in train_sample]\n",
    "train_outputs = [outputs[i] for i in train_sample]\n",
    "\n",
    "validation_inputs = [inputs[i] for i in validation_sample]\n",
    "validation_outputs = [outputs[i] for i in validation_sample]\n",
    "\n",
    "plt.plot(train_inputs, train_outputs, 'ro', label='training data')  #train data are plotted by red and circle sign\n",
    "plt.plot(validation_inputs, validation_outputs, 'g^',\n",
    "         label='validation data')  #test data are plotted by green and a triangle sign\n",
    "plt.title('train and validation data')\n",
    "plt.xlabel('GDP capita')\n",
    "plt.ylabel('happiness')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "ace7319a689d1e7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "regressor = MyGDRegression()\n",
    "\n",
    "regressor.fit(train_inputs, train_outputs)\n",
    "\n",
    "predicted = regressor.predict(validation_inputs)\n",
    "print(predicted)"
   ],
   "id": "e65844431301aae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "no_of_points = 1000\n",
    "xref = []\n",
    "t = [d[0] for d in train_inputs]\n",
    "val = min(t)\n",
    "step = (max(t) - min(t)) / no_of_points\n",
    "for i in range(1, no_of_points):\n",
    "    xref.append(val)\n",
    "    val += step\n",
    "yref = [regressor.eval([el]) for el in xref]\n",
    "\n",
    "plt.plot(train_inputs, train_outputs, 'ro', label='training data')\n",
    "plt.plot(xref, yref, 'b-', label='learnt model')\n",
    "plt.title('train data and the learnt model')\n",
    "plt.xlabel('GDP capita')\n",
    "plt.ylabel('happiness')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "338bae13687f1e21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "computed_validation_outputs = regressor.predict(validation_inputs)\n",
    "\n",
    "plt.plot(validation_inputs, computed_validation_outputs, 'yo', label='computed test data')\n",
    "plt.plot(validation_inputs, validation_outputs, 'g^', label='real test data')\n",
    "plt.title('computed validation and real validation data')\n",
    "plt.xlabel('GDP capita')\n",
    "plt.ylabel('happiness')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "83d6fa9a076a4aa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_error():\n",
    "    error = 0.0\n",
    "    for t1, t2 in zip(computed_validation_outputs, validation_outputs):\n",
    "        error += (t1 - t2) ** 2\n",
    "    error = error / len(validation_outputs)\n",
    "    print('prediction error (manual): ', error)\n",
    "    \n",
    "    error2 = 0.0\n",
    "    for t1, t2 in zip(computed_validation_outputs, validation_outputs):\n",
    "        error2 += abs(t1 - t2)\n",
    "    error2 = error2 / len(validation_outputs)\n",
    "    print('predicition error2 (manual with MAE)', error2)\n",
    "    \n",
    "compute_error()"
   ],
   "id": "f0a4e019f2c68728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_folds = 3\n",
    "n_sample = len(inputs)\n",
    "fold_size = n_sample // n_folds\n",
    "\n",
    "indexes = [i for i in range(n_sample)]\n",
    "shuffle(indexes)\n",
    "\n",
    "for i in range(n_folds):\n",
    "    validation_indices = indexes[i * fold_size: (i + 1) * fold_size]\n",
    "    train_indices = [idx for idx in indexes if idx not in validation_indices]\n",
    "    for j in range(i * fold_size):\n",
    "        train_indices.append(j)\n",
    "    for j in range((i + 1) * fold_size, n_sample):\n",
    "        train_indices.append(j)\n",
    "    \n",
    "    train_inputs_v = [inputs[i] for i in train_indices]\n",
    "    train_outputs_v = [outputs[i] for i in train_indices]\n",
    "\n",
    "    validation_inputs_v = [inputs[i] for i in validation_indices]\n",
    "    validation_outputs_v = [outputs[i] for i in validation_indices]\n",
    "        \n",
    "    model = MyGDRegression()\n",
    "    model.fit(train_inputs_v, train_outputs_v)\n",
    "    prediction = model.predict(validation_inputs_v)\n",
    "    \n",
    "    error = 0.0\n",
    "    for t1, t2 in zip(prediction, validation_outputs_v):\n",
    "        error += (t1 - t2) ** 2\n",
    "    error = error / len(validation_outputs_v)\n",
    "    print('prediction error (manual): ', error)\n",
    "    \n",
    "    error2 = 0.0\n",
    "    for t1, t2 in zip(prediction, validation_outputs_v):\n",
    "        error2 += abs(t1 - t2)\n",
    "    error2 = error2 / len(validation_outputs_v)\n",
    "    print('predicition error2 (manual with MAE)', error2)\n"
   ],
   "id": "3f5f1bbf869870a9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
