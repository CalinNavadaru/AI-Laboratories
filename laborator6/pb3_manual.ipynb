{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from random import random\n",
    "\n",
    "\n",
    "def sigmoid(value):\n",
    "    from math import exp\n",
    "    return 1 / (1 + exp(-value))\n",
    "\n",
    "\n",
    "class MyLogisticRegressionMultipleLabels:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.intercept_ = []\n",
    "        self.coefficient_ = []\n",
    "\n",
    "    def fit_batch(self, x, y, learning_rate=0.001, no_epochs=1000):\n",
    "        self.coefficient_ = []\n",
    "        self.intercept_ = []\n",
    "        labels = list(set(y))\n",
    "        for label in labels:\n",
    "            coefficient = [random() for _ in range(len(x[0]) + 1)]\n",
    "            for _ in range(no_epochs):\n",
    "                errors = [0] * len(coefficient)\n",
    "                for input, output in zip(x, y):\n",
    "                    y_computed = sigmoid(self.evaluate(input, coefficient))\n",
    "                    error = y_computed - 1 if output == label else y_computed\n",
    "                    for i, xi in enumerate([1] + list(input)):\n",
    "                        errors[i] += error * xi * y_computed * (1 - y_computed)\n",
    "                for i in range(len(coefficient)):\n",
    "                    coefficient[i] = coefficient[i] - learning_rate * errors[i]\n",
    "            self.intercept_.append(coefficient[0])\n",
    "            self.coefficient_.append(coefficient[1:])\n",
    "\n",
    "    def evaluate(self, xi, coefficient):\n",
    "        yi = coefficient[0]\n",
    "        for j in range(len(xi)):\n",
    "            yi += coefficient[j + 1] * xi[j]\n",
    "        return yi\n",
    "\n",
    "    def predict_one_sample(self, sample_features):\n",
    "        predictions = []\n",
    "        for intercept, coefficient in zip(self.intercept_, self.coefficient_):\n",
    "            computed_value = self.evaluate(sample_features, [intercept] + coefficient)\n",
    "            predictions.append(sigmoid(computed_value))\n",
    "        return predictions.index(max(predictions))\n",
    "\n",
    "    def predict(self, in_test):\n",
    "        computed_labels = [self.predict_one_sample(sample) for sample in in_test]\n",
    "        return computed_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53)\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "input_data = iris.data.features\n",
    "output_data = iris.data.targets"
   ],
   "id": "52fefaa6e72ecdb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_data_list = [[float(sl), float(sw), float(pl), float(pw)] for sl, sw, pl, pw in\n",
    "                   zip(input_data['sepal length'], input_data['sepal width'], input_data['petal length'],\n",
    "                       input_data['petal width'])]"
   ],
   "id": "1948398bad1af5b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "d = {}\n",
    "i = 0\n",
    "for x in output_data['class']:\n",
    "    if d.get(x, -1) == -1:\n",
    "        d[x] = i / 3\n",
    "        i += 1\n",
    "\n",
    "output_data_list = []\n",
    "for x in output_data['class']:\n",
    "    output_data_list.append(d[x])"
   ],
   "id": "c83a4186e9204be7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalize_feature(data_arg):\n",
    "    minimum = min(data_arg)\n",
    "    maximum = max(data_arg)\n",
    "    for i in range(len(data_arg)):\n",
    "        data_arg[i] = (data_arg[i] - minimum) / (maximum - minimum)\n",
    "\n",
    "\n",
    "def normalize(train_data_arg):\n",
    "    new_train_data = [[] for _ in range(len(train_data_arg))]\n",
    "    for i in range(len(train_data_arg[0])):\n",
    "        aux_list = [train_data_arg[r][i] for r in range(len(train_data_arg))]\n",
    "        normalize_feature(aux_list)\n",
    "        for t in range(len(train_data_arg)):\n",
    "            new_train_data[t].append(aux_list[t])\n",
    "\n",
    "    return new_train_data\n",
    "\n",
    "\n",
    "def normalisation(train_data, test_data):\n",
    "    if not isinstance(train_data[0], list):\n",
    "        train_data = [[d] for d in train_data]\n",
    "        test_data = [[d] for d in test_data]\n",
    "\n",
    "        normalised_train_data = normalize(train_data)\n",
    "        normalised_test_data = normalize(test_data)\n",
    "\n",
    "        normalised_train_data = [d[0] for d in normalised_train_data]\n",
    "        normalised_test_data = [d[0] for d in normalised_test_data]\n",
    "    else:\n",
    "        normalised_train_data = normalize(train_data)\n",
    "        normalised_test_data = normalize(test_data)\n",
    "\n",
    "    return normalised_train_data, normalised_test_data"
   ],
   "id": "d66a03469c0dd990",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import shuffle\n",
    "\n",
    "indexes = [i for i in range(len(input_data_list))]\n",
    "shuffle(indexes)\n",
    "train_indexes = indexes[:int(0.75 * len(input_data_list))]\n",
    "train_input_data = [input_data_list[i] for i in range(len(input_data_list)) if i in train_indexes]\n",
    "test_input_data = [input_data_list[i] for i in range(len(input_data_list)) if i not in train_indexes]\n",
    "train_output_data = [output_data_list[i] for i in range(len(input_data_list)) if i in train_indexes]\n",
    "test_output_data = [output_data_list[i] for i in range(len(input_data_list)) if i not in train_indexes]\n",
    "\n",
    "train_input_data, test_input_data = normalisation(train_input_data, test_input_data)\n",
    "\n",
    "model = MyLogisticRegressionMultipleLabels()\n",
    "\n",
    "model.fit_batch(train_input_data, train_output_data)\n",
    "\n",
    "predicted = model.predict(test_input_data)\n",
    "print(predicted)"
   ],
   "id": "8445c0f5c8a49f14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "err = 0\n",
    "for y, r in zip(predicted, test_output_data):\n",
    "    err += (y - r) ** 2\n",
    "\n",
    "print(f\"Error {err / len(test_output_data)}\")"
   ],
   "id": "fafe723a6351cd03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = [[5.35, 3.85, 1.25, 0.4]]\n",
    "result = model.predict(a)\n",
    "if result[0] == 0:\n",
    "    print(\"setosa\")\n",
    "elif result[0] == 1:\n",
    "    print(\"versicolor\")\n",
    "else:\n",
    "    print(\"virginica\")"
   ],
   "id": "84dce234cd94fd14",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
